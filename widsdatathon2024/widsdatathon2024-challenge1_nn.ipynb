{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils.eval_helpers import calculate_binary_classification_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "device = (\n",
    "    \"cuda\" \n",
    "    if torch.cuda.is_available() \n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed(device)\n",
    "    torch.cuda.manual_seed_all(device)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "elif device == \"cpu\":\n",
    "    torch.manual_seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(x_arr, y_arr, bs=None, is_train=False):\n",
    "    x_t, y_t = map(\n",
    "        lambda x: torch.tensor(x, device=device, dtype=torch.float32), (x_arr, y_arr)\n",
    "    )\n",
    "    ds = TensorDataset(x_t, y_t)\n",
    "    shuffle = True if is_train else False\n",
    "    dl = DataLoader(dataset=ds, batch_size=bs, shuffle=shuffle, drop_last=False)\n",
    "    return dl, x_t, y_t\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def get_model(input_dim, hidden_dim=None, output_dim=1, lr=0.001):\n",
    "    if hidden_dim:\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    else:\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    print(f'#Parameters: {count_parameters(model)}')\n",
    "    return model, optimizer\n",
    "\n",
    "def calculate_loss_and_metrics(model, x, y, loss_func=None, threshold=0.5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_prob = model(x)\n",
    "        y_pred = (y_prob >= threshold).int()\n",
    "        tensors = [y, y_pred, y_prob]\n",
    "        lists = [tensor.cpu().numpy().tolist() for tensor in tensors]\n",
    "        metrics_df = calculate_binary_classification_metrics(*lists)\n",
    "        if loss_func:\n",
    "            loss = loss_func(y_prob, y).item()\n",
    "            return loss, metrics_df\n",
    "    return None, metrics_df\n",
    "\n",
    "def fit(epochs, model, train_dl, loss_func, opt, log_dir, x_train, y_train, x_val, y_val):\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            lossb = loss_func(model(xb), yb)\n",
    "            lossb.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        train_loss, train_metrics_df = calculate_loss_and_metrics(model, x_train, y_train, loss_func)\n",
    "        val_loss, val_metrics_df = calculate_loss_and_metrics(model, x_val, y_val, loss_func)\n",
    "        writer.add_scalar('loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('loss/validation', val_loss, epoch)\n",
    "        for column in train_metrics_df.columns:\n",
    "            writer.add_scalar(f'{column}/train', train_metrics_df[column].values, epoch)\n",
    "        for column in val_metrics_df.columns:\n",
    "            writer.add_scalar(f'{column}/validation', val_metrics_df[column].values, epoch)\n",
    "        torch.save(model.state_dict(), Path(log_dir) / Path(f'model_weights_{epoch}.pth'))\n",
    "    writer.close()\n",
    "\n",
    "def evaluate_model(x_arr, y_arr, hidden_dim, weights_path):\n",
    "    _, x_val, y_val = get_data(x_arr, y_arr)\n",
    "    model, _ = get_model(x_val.shape[1], hidden_dim)\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=torch.device(device), weights_only=True), strict=True)\n",
    "    _, metrics_df = calculate_loss_and_metrics(model, x_val, y_val)\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_train_minmax_scaled.pkl', 'rb') as file:\n",
    "    X_train_minmax_scaled = pickle.load(file)\n",
    "# with open('X_train_minmax_scaled_resampled.pkl', 'rb') as file:\n",
    "#     X_train_minmax_scaled = pickle.load(file)\n",
    "with open('X_validation_minmax_scaled.pkl', 'rb') as file:\n",
    "    X_validation_minmax_scaled = pickle.load(file)\n",
    "with open('y_train.pkl', 'rb') as file:\n",
    "    y_train = pickle.load(file)\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "# with open('y_train_resampled.pkl', 'rb') as file:\n",
    "#     y_train = pickle.load(file)\n",
    "#     y_train = y_train.reshape(-1, 1)\n",
    "with open('y_validation.pkl', 'rb') as file:\n",
    "    y_validation = pickle.load(file)\n",
    "    y_validation = y_validation.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled = True\n",
    "bs = 64\n",
    "lr = 0.005\n",
    "epochs = 20\n",
    "input_dim = X_train_minmax_scaled.shape[1]\n",
    "hidden_dim = 5\n",
    "output_dim = 1\n",
    "loss_func = nn.BCELoss()\n",
    "log_name = f'resampled{resampled}-bs{bs}-lr{lr}'\n",
    "if hidden_dim:\n",
    "    log_name += f'-hidden_dim{hidden_dim}'\n",
    "log_dir = Path('runs') / Path(log_name)\n",
    "if log_dir.exists():\n",
    "    print(f\"Folder '{log_dir}' already exists.\")\n",
    "else:\n",
    "    print(f\"Folder '{log_dir}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, x_train, y_train = get_data(X_train_minmax_scaled, y_train, bs, is_train=True)\n",
    "_, x_val, y_val = get_data(X_validation_minmax_scaled, y_validation, bs)\n",
    "model, optimizer = get_model(input_dim, hidden_dim, output_dim, lr)\n",
    "fit(epochs, model, train_dl, loss_func, optimizer, log_dir, x_train, y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `hidden_dim=None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Parameters: 280\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.819347</td>\n",
       "      <td>0.793731</td>\n",
       "      <td>0.964966</td>\n",
       "      <td>0.871012</td>\n",
       "      <td>0.767066</td>\n",
       "      <td>0.793589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall  f1_score  balanced_accuracy   roc_auc\n",
       "0  0.819347   0.793731  0.964966  0.871012           0.767066  0.793589"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = evaluate_model(X_validation_minmax_scaled, \n",
    "                            y_validation, \n",
    "                            hidden_dim=None, \n",
    "                            weights_path='runs/resampledFalse-bs128-lr0.002/model_weights_8.pth')\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `hidden_dim=5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Parameters: 1406\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.819347</td>\n",
       "      <td>0.795224</td>\n",
       "      <td>0.961893</td>\n",
       "      <td>0.870654</td>\n",
       "      <td>0.768169</td>\n",
       "      <td>0.794745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall  f1_score  balanced_accuracy   roc_auc\n",
       "0  0.819347   0.795224  0.961893  0.870654           0.768169  0.794745"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = evaluate_model(X_validation_minmax_scaled, \n",
    "                            y_validation, \n",
    "                            hidden_dim=5, \n",
    "                            weights_path='runs/resampledFalse-bs64-lr0.005-hidden_dim5/model_weights_10.pth')\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The best model achieves an ROC-AUC score of 0.794745 by using an additional linear layer, which improves performance over the logistic-regressor-like model (which has no hidden layers). Resampling was not used, as it led to score degradation. However, both training and validation losses remain relatively high at approximately 0.46."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
