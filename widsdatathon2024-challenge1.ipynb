{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Overview](https://www.kaggle.com/competitions/widsdatathon2024-challenge1/overview)\n",
    "- Objective: Develop a model to predict if patients received a metastatic cancer diagnosis within 90 days of screening (i.e., `DiagPeriodL90D`) using a unique oncology dataset.\n",
    "- Motivation: \n",
    "    - Metastatic TNBC is considered the most aggressive TNBC and requires most urgent and timely treatment. Unnecessary delays in diagnosis and subsequent treatment can have devastating effects in these difficult cancers. Differences in the wait time to get treatment is a good proxy for disparities in healthcare access.\n",
    "    - The primary goal of building these models is to detect relationships between demographics of the patient with the likelihood of getting timely treatment. The secondary goal is to see if environmental hazards impact proper diagnosis and treatment.  #TODO: check this\n",
    "- Dataset\n",
    "    - Source: Provided by Gilead Sciences, originating from Health Verity and enriched with third-party geo-demographic data and zip code level toxicology data from NASA/Columbia University.\n",
    "    - Content: Information about demographics, diagnosis, treatment options, and insurance for patients diagnosed with breast cancer from 2015-2018.\n",
    "    - Highlighted Features:\n",
    "        - Demographics (e.g., age, gender, race, ...)\n",
    "        - Diagnosis and treatment details (e.g., breast cancer diagnosis code, metastatic cancer diagnosis code, metastatic cancer treatments, ...)\n",
    "        - Insurance information\n",
    "        - Geo (zip-code level) demographic data (e.g, income, education, rent, race, poverty, ...)\n",
    "        - Toxic air quality (zip-code level) data (e.g., Ozone, PM25 and NO2, ...)\n",
    "- Evaluation\n",
    "    - Metric: Area Under the Receiver Operating Characteristic (ROC) Curve (AUC-ROC).\n",
    "    - Leaderboard:\n",
    "        - During the competition: 51% of the test data.\n",
    "        - Final standings: 49% of the test data.\n",
    "- Submission Format\n",
    "    - File Format: CSV\n",
    "    - Columns:\n",
    "        - `patient_id` (integer)\n",
    "        - `DiagPeriodL90D` (percentage)\n",
    "    - Example:\n",
    "        ```\n",
    "        patient_id,DiagPeriodL90D\n",
    "        372069,.5\n",
    "        981264,.5\n",
    "        ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Dataset](https://www.kaggle.com/competitions/widsdatathon2024-challenge1/data)\n",
    "Roughly 18k records, each corresponds to a single patient and her Diagnosis Period\n",
    "- `training.csv`\n",
    "    - 12906 records\n",
    "    - 83 columns, the last column is `DiagPeriodL90D` (int64)\n",
    "- `test.csv`\n",
    "    - 5792 records\n",
    "    - 82 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts:\n",
    "- Don't remove records easily where certain columns are empty. You don't know if such data missing pattern indicates certain characteristics of patients which correlates to target prediction.\n",
    "- Ensure same pre- and post-processing for training and test data.\n",
    "- Logistic Regression as a prelimilary step to discover relevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Optional, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn style (default)\n",
    "sns.set_theme(context=\"notebook\", style=\"darkgrid\", palette=\"deep\", font=\"sans-serif\", font_scale=1, color_codes=True, rc=None)\n",
    "\n",
    "# font sizes\n",
    "title_fontsize = 14\n",
    "label_fontsize = 12\n",
    "tick_fontsize = 10\n",
    "text_fontsize = 10\n",
    "\n",
    "# random state\n",
    "random_state = 42\n",
    "\n",
    "# copy-on-write\n",
    "pd.set_option(\"mode.copy_on_write\", True)\n",
    "\n",
    "# maximum column width, number of rows and columns to display\n",
    "pd.set_option(\"display.max_colwidth\", None)  # no limit\n",
    "pd.set_option(\"display.max_rows\", None)      # no limit\n",
    "pd.set_option(\"display.max_columns\", None)   # no limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.read_csv('data/training.csv')\n",
    "df_training.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">From the `dtypes` (NumPy data types: `np.float64`, `np.int64`; Python's built-in type: `object`), we know that the missing values in all columns can only be `numpy.nan`, i.e., `NaN`.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">There are some records where all attributes are identical except for `patient_id`. After removing these duplicates (keeping the first occurrence), 12,870 records remain.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicates(df, id_col):\n",
    "    \"\"\"\n",
    "    Identifies and filters duplicates based on all columns except the specified ID column.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    id_col (str): The name of the ID column.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing only the duplicated rows.\n",
    "    list: List of columns to check for duplicates.\n",
    "    \"\"\"\n",
    "    columns_to_check = df.columns.difference([id_col]).to_list()\n",
    "    duplicates_mask = df.duplicated(subset=columns_to_check, keep=False)\n",
    "    duplicates_df = df[duplicates_mask].copy()\n",
    "    return duplicates_df, columns_to_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find duplicates except the `patient_id` column\n",
    "duplicates_df, columns_to_check = find_duplicates(df_training, 'patient_id')\n",
    "first_occurrence_df = duplicates_df.drop_duplicates(subset=columns_to_check)\n",
    "print('All Duplicated Rows (including the first occurrence):')\n",
    "print(duplicates_df.to_string(index=False))\n",
    "print(f'\\nTotal Number of Duplicated Rows (excluding the first occurrence): {len(duplicates_df) - len(first_occurrence_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "df_training_without_duplicates = df_training.drop_duplicates(subset=columns_to_check, ignore_index=True)\n",
    "print(f'Removed {len(df_training) - len(df_training_without_duplicates)} duplicated rows.')\n",
    "print(f'Current #Patients: {len(df_training_without_duplicates)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_without_duplicates.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_counts(df: pd.DataFrame, col: str, normalize: bool = True, dropna: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Computes the value counts for a specified column in a DataFrame, optionally normalizing and dropping missing values.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    col (str): The name of the column to compute value counts for.\n",
    "    normalize (bool, optional): If True, the value counts will be normalized to percentages. Defaults to True.\n",
    "    dropna (bool, optional): If True, missing values will be dropped from the value counts. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the value counts (*100 if normalized).\n",
    "    \"\"\"\n",
    "    # compute value counts\n",
    "    value_counts = df[col].value_counts(normalize=normalize, dropna=dropna)\n",
    "    \n",
    "    # multiply by 100 if normalized\n",
    "    if normalize:\n",
    "        value_counts *= 100\n",
    "    \n",
    "    return value_counts.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_value_counts(df: pd.DataFrame, col: str, filter_col: str, filter_values: list, normalize: bool = True, dropna: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Computes and combines the value counts for a specified column in the original DataFrame and filtered DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    col (str): The name of the column to compute value counts for.\n",
    "    filter_col (str): The name of the column to filter on.\n",
    "    filter_values (list): A list of values to filter by in the filter_col.\n",
    "    normalize (bool, optional): If True, the value counts will be normalized to percentages. Defaults to True.\n",
    "    dropna (bool, optional): If True, missing values will be dropped from the value counts. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the combined value counts.\n",
    "    \"\"\"\n",
    "    # compute value counts for the original DataFrame\n",
    "    original_counts = get_value_counts(df, col, normalize=normalize, dropna=dropna)\n",
    "    original_counts.columns = ['All (%)']\n",
    "\n",
    "    # initialize an empty DataFrame to store the combined results\n",
    "    combined_df = original_counts\n",
    "\n",
    "    # compute value counts for each filter value and merge into the combined DataFrame\n",
    "    for value in filter_values:\n",
    "        filtered_df = df[df[filter_col] == value]\n",
    "        filtered_counts = get_value_counts(filtered_df, col, normalize=normalize, dropna=dropna)\n",
    "        filtered_counts.columns = [f'{filter_col}={value} (%)']\n",
    "        combined_df = combined_df.join(filtered_counts, how='outer')\n",
    "\n",
    "    # reindex the combined DataFrame to match the original index order\n",
    "    combined_df = combined_df.reindex(original_counts.index)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_nan(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Highlight NaN values in the DataFrame and rows where the index is NaN.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to apply the styling to.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with applied styles.\n",
    "    \"\"\"\n",
    "    def highlight_row(row):\n",
    "        if pd.isna(row.name):\n",
    "            return ['background-color: gray'] * len(row)\n",
    "        return ['background-color: gray' if pd.isna(v) else '' for v in row]\n",
    "    \n",
    "    return df.style.apply(highlight_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category_distribution(df: pd.DataFrame, cat_col: str, index_labels: Optional[List[Tuple[int, str]]] = None) -> None:\n",
    "    \"\"\"\n",
    "    Plots the distribution of a categorical column in a DataFrame, normalizing the value counts and optionally setting a specific order.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    cat_col (str): The name of the categorical column to plot.\n",
    "    index_labels (Optional[List[Tuple[int, str]]]): A list of tuples where each inner tuple contains an index and its corresponding label.\n",
    "    \"\"\"\n",
    "    # compute value counts\n",
    "    series = df[cat_col].copy()\n",
    "    series.name = None\n",
    "    value_counts_normalized = series.value_counts(normalize=True, dropna=False)\n",
    "\n",
    "    if index_labels:\n",
    "        # define the order of the categories\n",
    "        sorted_index_labels = sorted(index_labels)\n",
    "        order = [index for index, _ in sorted_index_labels]\n",
    "        # reindex the result to set the order\n",
    "        value_counts_normalized = value_counts_normalized.reindex(order)\n",
    "\n",
    "    # plot\n",
    "    value_counts_normalized.plot(kind='barh', figsize=(10, min(len(value_counts_normalized.index), 8)))\n",
    "    plt.title(f'{cat_col} Distribution (%)', fontsize=title_fontsize)\n",
    "    plt.xlim([0, 1])\n",
    "    if index_labels:\n",
    "        plt.yticks(ticks=order, labels=[f'{index} ({label})' for index, label in sorted_index_labels], fontsize=tick_fontsize)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram_with_percentages(df: pd.DataFrame, num_col: str, bins: Union[int, List[int]]) -> None:\n",
    "    \"\"\"\n",
    "    Plot a histogram for a specified numerical column of a DataFrame, showing the percentage each bin represents.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the data.\n",
    "    num_col (str): The name of the numerical column to plot.\n",
    "    bins (int or List[int]): The number of bins or the boundaries of the bins.\n",
    "    \"\"\"\n",
    "    # check if the column exists and is numerical and has no missing values\n",
    "    if num_col not in df.columns:\n",
    "        raise ValueError(f\"Column '{num_col}' not found in the DataFrame.\")\n",
    "    if not pd.api.types.is_numeric_dtype(df[num_col]):\n",
    "        raise ValueError(f\"Column '{num_col}' is not numerical.\")\n",
    "    if df[num_col].isna().any():\n",
    "        raise ValueError(f\"Column '{num_col}' contains missing values. Please handle or remove them before plotting.\")\n",
    " \n",
    "    # calculate the weights to represent percentages\n",
    "    total_count = len(df[num_col])\n",
    "    weights = [100 / total_count] * total_count\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    hist = sns.histplot(x=df[num_col], bins=bins, weights=weights)\n",
    "    for p in hist.patches:\n",
    "        height = p.get_height()\n",
    "        hist.text(p.get_x() + p.get_width() / 2., height + 0.5, f'{height:.1f}', ha=\"center\", fontsize=text_fontsize)\n",
    "    plt.title(f'{num_col} Distribution', fontsize=title_fontsize)\n",
    "    plt.xlabel(num_col, fontsize=label_fontsize)\n",
    "    plt.ylabel('Percentage', fontsize=label_fontsize)\n",
    "    if isinstance(bins, int):\n",
    "        bins = pd.cut(df[num_col], bins=bins, retbins=True)[1]\n",
    "    plt.xticks(ticks=bins, fontsize=tick_fontsize)\n",
    "    plt.yticks(fontsize=tick_fontsize)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_side_by_side_histogram_with_percentages(df: pd.DataFrame, num_col: str, filter_col: str, filter_values: List, bins: Union[int, List[int]]) -> None:\n",
    "    \"\"\"\n",
    "    Plot a side-by-side histogram for a specified numerical column of a DataFrame, showing the percentage each bin represents for both the original and filtered distributions.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the data.\n",
    "    num_col (str): The name of the numerical column to plot.\n",
    "    filter_col (str): The name of the column to filter on.\n",
    "    filter_values (list): A list of values to filter by in the filter_col.\n",
    "    bins (int or List[int]): The number of bins or the boundaries of the bins.\n",
    "    \"\"\"\n",
    "    # check if the columns exist and are numerical and have no missing values\n",
    "    if num_col not in df.columns:\n",
    "        raise ValueError(f\"Column '{num_col}' not found in the DataFrame.\")\n",
    "    if filter_col not in df.columns:\n",
    "        raise ValueError(f\"Column '{filter_col}' not found in the DataFrame.\")\n",
    "    if not pd.api.types.is_numeric_dtype(df[num_col]):\n",
    "        raise ValueError(f\"Column '{num_col}' is not numerical.\")\n",
    "    if df[num_col].isna().any():\n",
    "        raise ValueError(f\"Column '{num_col}' contains missing values. Please handle or remove them before plotting.\")\n",
    "    \n",
    "    # calculate bin edges\n",
    "    if isinstance(bins, int):\n",
    "        bins = pd.cut(df[num_col], bins=bins, retbins=True)[1]\n",
    "    bins = np.array(bins)\n",
    "\n",
    "    # calculate bin centers\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    bin_widths = bins[1:] - bins[:-1]\n",
    "\n",
    "    # create a DataFrame to store the counts\n",
    "    counts_df = pd.DataFrame()\n",
    "\n",
    "    # calculate counts for the original data\n",
    "    original_counts, _ = np.histogram(df[num_col], bins=bins)\n",
    "    counts_df['All'] = original_counts\n",
    "\n",
    "    # calculate counts for the filtered data\n",
    "    for value in filter_values:\n",
    "        filtered_df = df[df[filter_col] == value]\n",
    "        filtered_counts, _ = np.histogram(filtered_df[num_col], bins=bins)\n",
    "        counts_df[f'{filter_col}={value}'] = filtered_counts\n",
    "\n",
    "    # normalize counts to percentages\n",
    "    counts_df = counts_df.div(counts_df.sum(axis=0)) * 100\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    cmap = plt.get_cmap('viridis')\n",
    "    colors = [cmap(i / len(counts_df.columns)) for i in range(len(counts_df.columns))]\n",
    "\n",
    "    for i, (col, color) in enumerate(zip(counts_df.columns, colors)):\n",
    "        for j, (center, width, count) in enumerate(zip(bin_centers, bin_widths, counts_df[col])):\n",
    "            ax.bar(center + (i - len(counts_df.columns) // 2) * (width / len(counts_df.columns)), count, width=width / (len(counts_df.columns)), alpha=0.7, color=color, label=col if j == 0 else \"\")\n",
    "\n",
    "    for i, col in enumerate(counts_df.columns):\n",
    "        for center, width, count in zip(bin_centers, bin_widths, counts_df[col]):\n",
    "            ax.text(center + (i - len(counts_df.columns) // 2) * (width / len(counts_df.columns)), count + 0.5, f'{count:.1f}', ha=\"center\", fontsize=tick_fontsize)\n",
    "\n",
    "    plt.title(f'{num_col} Distribution', fontsize=title_fontsize)\n",
    "    plt.xlabel(num_col, fontsize=label_fontsize)\n",
    "    plt.ylabel('Percentage', fontsize=label_fontsize)\n",
    "    plt.xticks(ticks=bins, fontsize=tick_fontsize)\n",
    "    plt.yticks(fontsize=tick_fontsize)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DiagPeriodL90D`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">Approximately 38% of patients did not receive a metastatic cancer diagnosis within 90 days of screening.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'DiagPeriodL90D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_value_counts(df_training_without_duplicates, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_category_distribution(df_training_without_duplicates, target_column, [(0, '>= 90 Days'), (1, '< 90 Days')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `patient_race`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">Race information is unknown for approximately 50% of patients. Among the known cases, the only race that comprises more than 10% is White, at about 28%. Patients with unknown race are slightly more likely to be undiagnosed within 90 days of screening, while patients identified as White are slightly more likely to be diagnosed timely.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_nan(get_combined_value_counts(df_training_without_duplicates, 'patient_race', target_column, [0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `payer_type`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">Around 47% of patients have commercial insurance. The proportions of patients with Medicaid or Medicare are similar, each close to 20%. Patients with unknown insurance types are slightly more likely to be diagnosed timely, while those with commercial insurance are slightly more likely to be undiagnosed within 90 days of screening.</span>  #TODO: check this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_nan(get_combined_value_counts(df_training_without_duplicates, 'payer_type', target_column, [0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `patient_state`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">The top 6 states where more than 5% of patients come from are CA (18.9%), TX (8.9%), NY (8.1%), MI (6.6%), IL (6.1%), and OH (5.9%). The tail of the distribution includes RI, NH, and MA, each at 0.00777%. Patients from some states, such as CA and MI, tend to receive more timely diagnoses compared to those from other states.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_nan(get_combined_value_counts(df_training_without_duplicates, 'patient_state', target_column, [0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `patient_zip3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">There are 739 zip3 codes with patient distribution ranging from 0.00777% to 1.8%.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_zip3_counts_df = get_combined_value_counts(df_training_without_duplicates, 'patient_zip3', target_column, [0, 1])\n",
    "print(f'#Zip3-codes: {len(patient_zip3_counts_df)}')\n",
    "highlight_nan(patient_zip3_counts_df.head(10))\n",
    "# highlight_nan(patient_zip3_counts_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `patient_age`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">This dataset includes patients ranging from 18 to 91 years old, with more than 80% of the patients aged between 40 and 80. Patients older than 60 are slightly more likely to be diagnosed timely, while younger patients are slightly more likely to be missed.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Min & max age: {df_training_without_duplicates['patient_age'].min()}, {df_training_without_duplicates['patient_age'].max()}')\n",
    "age_boundries = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]  # bins: [10-20), [20-30), [30-40), [40-50), [50-60), [60-70), [70-80), [80-90), [90-100]\n",
    "plot_side_by_side_histogram_with_percentages(df_training_without_duplicates, 'patient_age', target_column, [0, 1], age_boundries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `patient_gender`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">All patients are female.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_nan(get_value_counts(df_training_without_duplicates, 'patient_gender'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `bmi`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">Almost 70% of patients' BMI information is not available. For the available records, BMI ranges from 14.0 to 85.0. Most patients fall into the categories of 'Normal weight', 'Pre-obesity', and 'Obesity class I'. Patients with normal weights are slightly more likely to receive timely diagnoses, whereas those with higher BMIs are less likely to do so.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHO Classification of BMI\n",
    "\n",
    "| BMI Interval (kg/m²) | Category                |\n",
    "|----------------------|-------------------------|\n",
    "| < 18.5               | Underweight             |\n",
    "| 18.5 - 24.9          | Normal weight           |\n",
    "| 25 - 29.9            | Pre-obesity             |\n",
    "| 30 - 34.9            | Obesity class I         |\n",
    "| 35 - 39.9            | Obesity class II        |\n",
    "| ≥ 40                 | Obesity class III       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The proportion of missing BMI: {df_training_without_duplicates['bmi'].isna().sum() / len(df_training_without_duplicates) * 100:.1f}%')\n",
    "bmi_boundries = [0, 18.5, 25, 30, 35, 40, 85]  # bins: [0, 18.5), [18.5, 25), [25, 30), [30, 35), [35, 40), [40, 85]\n",
    "id_bmi_df = df_training_without_duplicates[['patient_id', 'bmi']].dropna()\n",
    "id_target_df = df_training_without_duplicates[['patient_id', target_column]]\n",
    "id_bmi_target_df = pd.merge(id_bmi_df, id_target_df, how='left', on='patient_id')\n",
    "plot_side_by_side_histogram_with_percentages(id_bmi_target_df, 'bmi', target_column, [0, 1], bmi_boundries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `breast_cancer_diagnosis_code`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">\n",
    "    <ol>\n",
    "        <li>The number of ICD-10 patients is 3.3 times that of ICD-9 patients. The most common codes are 174.9 (15.3%), C50.911 (13.9%), C50.912 (13.3%), and C50.919 (11.4%). Many other codes have fewer than 10 patients.\n",
    "        <li>Patients with a primary diagnosis code of 174.9 are more than 16 times as likely to remain undiagnosed within 90 days after screening. Generally, patients with ICD-9 codes are less likely to receive a timely diagnosis compared to those with ICD-10 codes.\n",
    "        <li>ICD-10 codes offer more detailed diagnoses for breast cancer compared to ICD-9 codes. While it is possible to map ICD-9 codes to ICD-10 codes, this process can alter the distribution of diagnosis codes. Therefore, direct conversion is not performed. However, some available mappings include: C50.9|174.9, C50.41|174.4, C50.81|174.8, C50.21|174.2, C50.11|174.1, C50.51|174.5, C50.31|174.3, C50.01|174.6. #TODO: experiment on this\n",
    "        <li>Some codes in the dataset (C50.929, C50.021, 175.9, C50.421) indicate breast cancer in males, which contradicts the information in the `patient_gender` column. These discrepancies suggest that there may be man-made errors present in the dataset, possibly introduced during data collection or data preparation. These records are not removed but require additional attention. #TODO: remove/move to validation set\n",
    "        <li>The code 198.81 represents a secondary malignant neoplasm of the breast, indicating that the cancer has metastasized to the breast from another part of the body. This differs from the other codes in the dataset, which represent primary breast cancer. Only one patient out of nine has `DiagPeriodL90D=1`. This definitely requires attention. #TODO: check this\n",
    "    </ol>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_icd10 = df_training_without_duplicates['breast_cancer_diagnosis_code'].str.startswith('C')\n",
    "icd10_df = df_training_without_duplicates[is_icd10]\n",
    "icd9_df = df_training_without_duplicates[~is_icd10]\n",
    "print(f'The ratio of ICD-10 codes to ICD-9 codes: {len(icd10_df)/len(icd9_df):.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_counts_df = get_combined_value_counts(df_training_without_duplicates, 'breast_cancer_diagnosis_code', target_column, [0, 1])\n",
    "code_desc_df = df_training_without_duplicates[['breast_cancer_diagnosis_code', 'breast_cancer_diagnosis_desc']].drop_duplicates()\n",
    "code_counts_desc_df = pd.merge(code_counts_df, code_desc_df, left_index=True, right_on='breast_cancer_diagnosis_code')\n",
    "highlight_nan(code_counts_desc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edge Cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_codes = ['C50929', 'C50021', '1759', 'C50421']\n",
    "secondary_code = '19881'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_code_df = df_training_without_duplicates[df_training_without_duplicates['breast_cancer_diagnosis_code'].isin(male_codes)]\n",
    "male_code_df[['patient_id', target_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_code_df = df_training_without_duplicates[df_training_without_duplicates['breast_cancer_diagnosis_code']==secondary_code]\n",
    "secondary_code_df[['patient_id', target_column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `breast_cancer_diagnosis_desc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">\n",
    "    <ol>\n",
    "        <li>Many words in the descriptions, such as 'Malignant'/'Malig', 'neoplasm'/'neopl', 'female', and 'breast', are not informative since they appear in almost every field. Removing these words can make the descriptions shorter and more concise. For example, the description 'Malignant neoplasm of breast (female), unspecified' can be reduced to 'unspecified' eventually.\n",
    "        <li>Some words have short forms, and using a uniform representation can reduce unnecessary variations. For this purpose, 'unsp' will be replaced by 'unspecified', and 'ovrlp' will be replaced by 'overlapping'.\n",
    "        <li>Each original description consists of 4 to 10 words. These descriptions specify the position of the neoplasm, such as the quadrant and side. After cleaning, the descriptions have been reduced to 1 to 7 words, with the single one-word description ('of') corresponding to C50.\n",
    "        <li>Through further preprocessing, the text will be converted to lowercase, and common English stop words (e.g., 'of', 'and', etc.) will be removed. Punctuation and special characters will also be eliminated implicitly.\n",
    "    </ol>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tokens(text: str, tokens: list) -> str:\n",
    "    \"\"\"\n",
    "    Removes specified tokens from the input text.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The input text string.\n",
    "    tokens (list): A list of tokens to remove from the input text.\n",
    "\n",
    "    Returns:\n",
    "    str: The filtered text with specified tokens removed.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in tokens]\n",
    "    \n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_tokens(text: str, replacements: dict) -> str:\n",
    "    \"\"\"\n",
    "    Replaces tokens in the input text based on a dictionary of token pairs.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The input text string.\n",
    "    replacements (dict): A dictionary where keys are tokens to be replaced and values are the replacement tokens.\n",
    "\n",
    "    Returns:\n",
    "    str: The text with tokens replaced according to the dictionary.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    replaced_words = [replacements.get(word, word) for word in words]\n",
    "    return ' '.join(replaced_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Counts the number of words in the input text, splitting by spaces.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The input text string.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of words in the text.\n",
    "    \"\"\"\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove tokens\n",
    "tokens_to_remove = ['Malignant', 'malignant', 'Malig',\n",
    "                    'neoplasm', 'neoplm', \n",
    "                    'female', '(female),',\n",
    "                    'breast', 'breast,']\n",
    "code_counts_desc_df['breast_cancer_diagnosis_desc_cleaned'] = code_counts_desc_df['breast_cancer_diagnosis_desc'].apply(lambda x: remove_tokens(x, tokens_to_remove))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace tokens\n",
    "token_replacements = {\n",
    "    'unsp': 'unspecified',\n",
    "    'ovrlp': 'overlapping'\n",
    "}\n",
    "code_counts_desc_df['breast_cancer_diagnosis_desc_cleaned'] = code_counts_desc_df['breast_cancer_diagnosis_desc_cleaned'].apply(lambda x: replace_tokens(x, token_replacements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_count = code_counts_desc_df['breast_cancer_diagnosis_desc'].apply(count_words)\n",
    "desc_cleaned_count = code_counts_desc_df['breast_cancer_diagnosis_desc_cleaned'].apply(count_words)\n",
    "print(f'Original #Words: min: {desc_count.min()}, max: {desc_count.max()}')\n",
    "print(f'Current #Words: min: {desc_cleaned_count.min()}, max: {desc_cleaned_count.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `metastatic_cancer_diagnosis_code`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">\n",
    "    <ol>\n",
    "        <li>All of the diagnosis codes are ICD-10 codes. The top 3 codes are C77.3(54.6%; Secondary and unspecified malignant neoplasm of axilla and upper limb lymph nodes), C79.51(14.2%; Secondary malignant neoplasm of bone), C77.9(5.9%; Secondary and unspecified malignant neoplasm of lymph node, unspecified).\n",
    "        <li>Patients with code C77.3 are slightly more likely to be diagnosed timely.\n",
    "        <li>Only 9 out of 43 diagnosis codes have metastatic first novel treatments, and these treatments occur in 24 out of all patients in the dataset (i.e., 0.186%). Among these patients, 8 were not diagnosed within 90 days after screening.\n",
    "    </ol>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_nan(get_combined_value_counts(df_training_without_duplicates, 'metastatic_cancer_diagnosis_code', target_column, [0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metastatic_code_counts_df = get_value_counts(df_training_without_duplicates, 'metastatic_cancer_diagnosis_code')\n",
    "metastatic_code_treatment_df = df_training_without_duplicates[['metastatic_cancer_diagnosis_code', 'metastatic_first_novel_treatment', 'metastatic_first_novel_treatment_type']].drop_duplicates().dropna()\n",
    "metastatic_code_counts_treatment_df = pd.merge(metastatic_code_counts_df, metastatic_code_treatment_df, left_index=True, right_on='metastatic_cancer_diagnosis_code')\n",
    "metastatic_code_counts_treatment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_with_first_novel_treatments_df = df_training_without_duplicates[df_training_without_duplicates['metastatic_first_novel_treatment'].notna()]\n",
    "patients_with_first_novel_treatments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `metastatic_first_novel_treatment` & `metastatic_first_novel_treatment_type`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">\n",
    "There are only two metastatic first novel treatments: PEMBROLIZUMAB and OLAPARIB. Both of these treatments are of the type Antineoplastics.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_nan(get_combined_value_counts(df_training_without_duplicates, 'metastatic_first_novel_treatment', target_column, [0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_nan(get_combined_value_counts(df_training_without_duplicates, 'metastatic_first_novel_treatment_type', target_column, [0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Region`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_nan(get_combined_value_counts(df_training_without_duplicates, 'Region', target_column, [0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Division`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_nan(get_combined_value_counts(df_training_without_duplicates, 'Division', target_column, [0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `population`, `density`, ..., `veteran`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">\n",
    "    <ol>\n",
    "        <li>All patients have complete or partial geographic (zip-code level) demographic data, with the exception of patient ID 224030, whose zip3 code (332) is the only occurrence of this value in the dataset. #TODO: check this\n",
    "        <li>In addition to that single patient, three patients with the zip3 code 772 also have missing values in columns starting with 'family', 'income_household', 'home', 'rent', 'self_employed', 'farmer', 'poverty', and 'limited_english'. These three patients are the only ones with this specific zip3 code. #TODO: check this\n",
    "    </ol>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_population_df = df_training_without_duplicates[df_training_without_duplicates['population'].isna()]\n",
    "na_population_zip3 = na_population_df['patient_zip3'].unique()\n",
    "print(na_population_zip3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_without_duplicates[df_training_without_duplicates['patient_zip3'] == na_population_zip3[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_family_size_df = df_training_without_duplicates[df_training_without_duplicates['family_size'].isna()]\n",
    "na_family_size_zip3 = na_family_size_df['patient_zip3'].unique()\n",
    "print(na_family_size_zip3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_without_duplicates[df_training_without_duplicates['patient_zip3'] == na_family_size_zip3[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Ozone`, `PM25`, `N02`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">\n",
    "29 patients with the zip3 code 967, 968, 998, 995, 996, and 999 lack information about environmental hazards. These patients are the only ones with these specific zip3 codes. #TODO: check this\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_ozone_df = df_training_without_duplicates[df_training_without_duplicates['Ozone'].isna()]\n",
    "na_ozone_zip3 = na_ozone_df['patient_zip3'].unique()\n",
    "print(na_ozone_zip3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_without_duplicates[df_training_without_duplicates['patient_zip3'].isin(na_ozone_zip3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check (Linear) Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">\n",
    "Among all originally numerical columns:\n",
    "    <ol>\n",
    "        <li>Slight positive correlation: e.g., patient_age, education_bachelors, patient_zip3,  income_individual_median, home_value\n",
    "        <li>Slight negative correlation: e.g., education_less_highschool, widowed, income_household_25_to_35, health_uninsured, commute_time\n",
    "    </ol>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = df_training_without_duplicates.corr(numeric_only=True)\n",
    "corr_df[target_column].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Edge Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_case_dfs = [male_code_df, secondary_code_df, na_family_size_df, na_ozone_df]  # na_population_df is a part of na_family_size_df\n",
    "edge_case_notes = ['male code', 'secondary code', 'na family size', 'na ozone']\n",
    "\n",
    "results = []\n",
    "for df, note in zip(edge_case_dfs, edge_case_notes):\n",
    "    extracted_df = df[[target_column]]\n",
    "    extracted_df['note'] = note\n",
    "    results.append(extracted_df)\n",
    "df_edge_cases = pd.concat(results, ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = ['patient_id', 'patient_gender']\n",
    "categorical_columns = ['patient_race', 'payer_type', 'patient_state', \n",
    "                       'patient_zip3',  \n",
    "                       'breast_cancer_diagnosis_code', 'metastatic_cancer_diagnosis_code', \n",
    "                       'metastatic_first_novel_treatment', 'metastatic_first_novel_treatment_type', \n",
    "                       'Region', 'Division']\n",
    "textual_column = 'breast_cancer_diagnosis_desc'\n",
    "textual_column_cleaned = textual_column + '_cleaned'\n",
    "numerical_columns = df_training_without_duplicates.columns.difference([target_column] + \n",
    "                                                                      columns_to_remove + \n",
    "                                                                      categorical_columns + \n",
    "                                                                      [textual_column]).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. remove patient_id, patient_gender\n",
    "df_training_without_ids_genders = df_training_without_duplicates.drop(columns=columns_to_remove)\n",
    "\n",
    "# 2. categorical -> numerical\n",
    "# fill NaN values with 'unknown'\n",
    "df_training_without_ids_genders[categorical_columns] = df_training_without_ids_genders[categorical_columns].fillna('unknown')\n",
    "# encode\n",
    "le = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    df_training_without_ids_genders[col] = le.fit_transform(df_training_without_ids_genders[col])\n",
    "\n",
    "# 3. textual -> numerical\n",
    "# clean\n",
    "df_training_without_ids_genders[textual_column_cleaned] = df_training_without_ids_genders[textual_column].apply(lambda x: remove_tokens(x, tokens_to_remove))\n",
    "df_training_without_ids_genders[textual_column_cleaned] = df_training_without_ids_genders[textual_column_cleaned].apply(lambda x: replace_tokens(x, token_replacements))\n",
    "# tfidf  #TODO: other options?\n",
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words='english')  #TODO: ngram\n",
    "tfidf_matrix = vectorizer.fit_transform(df_training_without_ids_genders[textual_column_cleaned])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "prefix = 'tfidf_'\n",
    "new_feature_names = [prefix + name for name in feature_names]\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=new_feature_names)\n",
    "df_training_with_text_encoded = pd.concat([df_training_without_ids_genders, tfidf_df], axis=1)\n",
    "df_training_prepared = df_training_with_text_encoded.drop(columns=[textual_column, textual_column_cleaned])\n",
    "\n",
    "# 4. numerical\n",
    "# fill NaN values with -1.0  #TODO: best practices?\n",
    "df_training_prepared[numerical_columns] = df_training_prepared[numerical_columns].fillna(-1.0)\n",
    "\n",
    "df_training_prepared.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_training_prepared.drop(target_column, axis=1)\n",
    "y = df_training_prepared[target_column]\n",
    "\n",
    "X_train, X_validation, y_train, y_validation, train_indices, validation_indices = train_test_split(\n",
    "    X, y, np.arange(len(X)), test_size=0.2, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_partition(index: int, train_indices: np.ndarray, validation_indices: np.ndarray) -> str:\n",
    "    \"\"\"\n",
    "    Determine the partition ('train' or 'validation') for a given index.\n",
    "\n",
    "    Parameters:\n",
    "    - index (int): The index to check.\n",
    "    - train_indices (numpy.ndarray): Array of indices for the training set.\n",
    "    - validation_indices (numpy.ndarray): Array of indices for the validation set.\n",
    "\n",
    "    Returns:\n",
    "    - str: 'train' if the index is in train_indices, 'validation' if the index is in validation_indices.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If the index is not found in either train_indices or validation_indices.\n",
    "    \"\"\"\n",
    "    if index in train_indices:\n",
    "        return 'train'\n",
    "    elif index in validation_indices:\n",
    "        return 'validation'\n",
    "    else:\n",
    "        raise ValueError(f\"Index {index} not found in either train_indices or validation_indices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edge_cases['partition'] = df_edge_cases.index.map(lambda idx: determine_partition(idx, train_indices, validation_indices))\n",
    "df_edge_cases['prediction'] = np.nan\n",
    "edge_case_validation_indices = df_edge_cases[df_edge_cases['partition'] == 'validation'].index.to_list()\n",
    "edge_case_prediction_indices = [np.where(validation_indices == idx)[0][0] for idx in edge_case_validation_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization (mean=0, variance=1) is generally preferred for algorithms that assume a Gaussian distribution of the input data (e.g., linear regression, logistic regression, SVM with RBF kernel).\n",
    "# Min-Max Scaling (min=0, max=1) is useful for algorithms that do not assume a specific distribution and are sensitive to the range of input data (e.g., k-nearest neighbors, neural networks).\n",
    "# Some algorithms, like decision trees and random forests, are not affected by the scale of the features and do not require normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_validation_scaled = scaler.transform(X_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=random_state)\n",
    "X_train_scaled_resampled, y_train_resampled = ros.fit_resample(X_train_scaled, y_train)\n",
    "print(f'Target Distribution (after Data Splitting): {Counter(y_train)}')\n",
    "print(f'Target Distribution (after Resampling): {Counter(y_train_resampled)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_diff(df: pd.DataFrame, col1: str, col2: str):\n",
    "    \"\"\"\n",
    "    Highlight rows where the values in the specified columns are different for non-missing rows.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to apply the styling to.\n",
    "    col1 (str): The name of the first column to compare.\n",
    "    col2 (str): The name of the second column to compare.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with applied styles.\n",
    "    \"\"\"\n",
    "    def highlight_row(row):\n",
    "        if (row[col1] != row[col2]) and (pd.notna(row[col1])) and (pd.notna(row[col2])):\n",
    "            return ['background-color: yellow'] * len(row)\n",
    "        return [''] * len(row)\n",
    "    \n",
    "    return df.style.apply(highlight_row, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_gt: List[int], y_pred: List[int], y_prob: List[float]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluate a binary classification model using various metrics.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_gt : List[int]\n",
    "        Ground truth labels (0 or 1).\n",
    "    y_pred : List[int]\n",
    "        Predicted labels (0 or 1).\n",
    "    y_prob : List[float]\n",
    "        Probability estimates for the positive class (1).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing the evaluation metrics: accuracy, precision, recall, f1_score, balanced_accuracy, and auc.\n",
    "\n",
    "    Metrics:\n",
    "    --------\n",
    "    - accuracy: (TP + TN) / (TP + TN + FP + FN)\n",
    "    - precision: TP / (TP + FP)\n",
    "      The ability of the classifier not to label as positive a sample that is negative.\n",
    "    - recall/TPR: TP / (TP + FN)\n",
    "      The ability of the classifier to find all the positive samples.\n",
    "    - f1_score: 2 * precision * recall / (precision + recall)\n",
    "    - balanced_accuracy\n",
    "      The average of recall obtained on each class.\n",
    "    - FPR: FP / (FP + TN)\n",
    "      The proportion of actual negative cases that are incorrectly identified as positive by the model.\n",
    "    - auc\n",
    "      Calculated using TPR and FPR at various threshold settings.\n",
    "      https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_gt, y_pred)\n",
    "    precision = precision_score(y_gt, y_pred, pos_label=1, average='binary')\n",
    "    recall = recall_score(y_gt, y_pred, pos_label=1, average='binary')\n",
    "    f1 = f1_score(y_gt, y_pred, pos_label=1, average='binary')\n",
    "    balanced_accuracy = balanced_accuracy_score(y_gt, y_pred)\n",
    "    auc = roc_auc_score(y_gt, y_prob)\n",
    "    return pd.DataFrame([[accuracy, precision, recall, f1, balanced_accuracy, auc]], \n",
    "                        columns=['accuracy', 'precision', 'recall', 'f1_score', 'balanced_accuracy', 'auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">\n",
    "    <ol>\n",
    "        <li>When using the L2 penalty, similar top coefficients are observed (no zero coefficients anymore), except for 'population', which becomes a top positive coefficient.\n",
    "        <li>When using resampled data, the recall for class 0 increases by 0.01, while all other metrics degrade slightly.\n",
    "     </ol>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty=\"l1\", C=1.0, random_state=random_state, solver=\"liblinear\", max_iter=100, verbose=0)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model.coef_[0]\n",
    "})\n",
    "feature_importance.sort_values(by='Coefficient', ascending=False, inplace=True)\n",
    "\n",
    "print(f'Top 10 Features with Positive Coefficients: \\n{feature_importance.head(10)['Feature'].to_list()}\\n')\n",
    "print(f'Top 10 Features with Negative Coefficients: \\n{feature_importance.tail(10)['Feature'].to_list()}\\n')\n",
    "print(f'All Features with Zero Coefficients: \\n{feature_importance[feature_importance['Coefficient']==0.]['Feature'].to_list()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_validation_scaled)\n",
    "y_prob = model.predict_proba(X_validation_scaled)[:, 1]\n",
    "evaluate_model(y_validation, y_pred, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edge_cases.loc[df_edge_cases['partition'] == 'validation', 'prediction'] = y_pred[edge_case_prediction_indices]\n",
    "highlight_diff(df_edge_cases, target_column, 'prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">\n",
    "    <ol>\n",
    "        <li>Using resampled data slightly improves the AUC.\n",
    "        <li>The most important features differ from those in logistic regression. For example, 'education_highschool', 'income_household_six_figure', and 'education_college_or_above' are considered important here but irrelevant in logistic regression.\n",
    "     </ol>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=random_state)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "})\n",
    "feature_importance.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "\n",
    "print(f'10 Most Important Features: \\n{feature_importance.head(10)['Feature'].to_list()}\\n')\n",
    "print(f'10 Least Important Features: \\n{feature_importance.tail(10)['Feature'].to_list()}\\n')\n",
    "\n",
    "print(f'Depth of the tree: {model.get_depth()}')\n",
    "print(f'Number of leaves: {model.get_n_leaves()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100, 50))\n",
    "plot_tree(model, feature_names=X.columns, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_validation)\n",
    "y_prob = model.predict_proba(X_validation)[:, 1]\n",
    "evaluate_model(y_validation, y_pred, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edge_cases.loc[df_edge_cases['partition'] == 'validation', 'prediction'] = y_pred[edge_case_prediction_indices]\n",
    "highlight_diff(df_edge_cases, target_column, 'prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ffed29;\">\n",
    "    <ol>\n",
    "        <li>Using resampled data slightly degrades the AUC.\n",
    "        <li>The most important features differ from those in logistic regression. For example, 'tfidf_quadrant', 'tfidf_left', 'tfidf_upper' and 'tfidf_specified' are considered important here but irrelevant in logistic regression.\n",
    "     </ol>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=115, criterion='gini', max_depth=5, \n",
    "                               oob_score=True, random_state=random_state, verbose=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "})\n",
    "feature_importance.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "\n",
    "print(f'10 Most Important Features: \\n{feature_importance.head(10)['Feature'].to_list()}\\n')\n",
    "print(f'10 Least Important Features: \\n{feature_importance.tail(10)['Feature'].to_list()}\\n')\n",
    "\n",
    "print(f'Out-of-bag score: {model.oob_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_validation)\n",
    "y_prob = model.predict_proba(X_validation)[:, 1]\n",
    "evaluate_model(y_validation, y_pred, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edge_cases.loc[df_edge_cases['partition'] == 'validation', 'prediction'] = y_pred[edge_case_prediction_indices]\n",
    "highlight_diff(df_edge_cases, target_column, 'prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Wids2024DevEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
